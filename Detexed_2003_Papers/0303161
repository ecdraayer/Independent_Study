













18.5truecm
22truecm
0truecm
-1truecm
-1truecm
e  
^Q _#1 ^Q ^ #2   
V  
 
 
F  
n  
 
res _ 
[20pt] 

equation section 

theorem Theorem [section]
examp Example [section]
coroll Corollary [section]
examps Examples [section]
exercise Exercise [section]
fact Fact [section]
lemma Lemma [section]
remark Remark [section]
mod  
remarks [remark]Remarks 
proposition Proposition [section]
definition Definition [section]
 
 
 
 Tr  
A  
B  
B  
U  
V  
A  
 
  
1  
 
  
 
  
 
 .
 enumerate  
 
  
 
  
 
 . enumerate  
 
  
 
  
 
  

 
  
*  
 
C  
a  
b  
 
R  
N  
P  
h  
H  
g  
Z  
  
  



 
CRM-2916 (2003)

Saclay-T03/028

 
 
Mixed Correlation Functions of  the Two-Matrix Model 



  M.
Bertola (bertola@mathstat.concordia.ca) , 
  B. Eynard 
(eynard@spht.saclay.cea.fr) 


 
 Department of Mathematics and
Statistics, Concordia University
 7141 Sherbrooke W., Montreal, Quebec,
Canada H4B 1R6  
 
 Centre de recherches mathematiques,
Universite de Montreal
 C. P. 6128, succ. centre ville, Montreal,
Quebec, Canada H3C 3J7  

 Service de Physique Theorique, CEA/Saclay 
 Orme des
Merisiers F-91191 Gif-sur-Yvette Cedex, FRANCE   


Abstract 
 
 

We compute the correlation functions mixing  the powers of 
two non-commuting random matrices within the  same trace. 
The angular part of the integration was partially known in the literature
: we  pursue the calculation and carry out the
eigenvalue integration reducing the problem to the construction of
the associated biorthogonal polynomials.
The generating function of these correlations becomes then
 a determinant involving the recursion coefficients
of the biorthogonal polynomials.
 













Introduction and main result 

Random matrix models were first introduced in the context of nuclear physics in 
order to describe the energy levels statistics for very large
nuclei.
Wigner proposed the hypothesis that these were distributed as the eigenvalues of a 
matrix with random entries.
Later random matrix models were used in many areas of physics and mathematics.

An important application of random matrices is to 2d gravity, that is, statistical physics on a random surface.
In fact, the perturbative expansion of a matrix integral can be
accomplished by drawing Feynman graphs on fixed-genus surfaces. 
 Matrix integration can therefore encode the summation over the  set of discretized surfaces 
(possibly carrying some type of matter).

When the parameters of the model are fine-tuned near a critical point the 
average graph's size diverges and macroscopic graphs dominate the sum,
so that 
 suitable critical limits can represent  
statistical models over smooth surfaces.
The  smooth surfaces that one describes with the aid of matrix models 
 have properties of scale invariance: this means that the  critical points of matrix 
integrals are related to representations of the conformal group. We
recall that its  finite dimensional representations are classified by 
two integers :
it is known that one-matrix-models provide
instances of  -irreps only, where as 
two-matrix-models allow to obtain -representations.

Possibly the first such application of the two-matrix-model was to describe the Ising model on a 
random surface; in this case the Ising ferromagnetic transition corresponds to the conformal 
minimal model .
To see this, one should associate a color (or spin)  or  to each matrix
so that the
vertices of one matrix are labelled with a plus sign
 and the vertices of 
the other matrix with a minus sign.
 Then the Feynman graphs generated by a two 
matrix model represent discrete surfaces carrying spins (+ and -),
i.e. an  Ising model on a random surface.

The correlation functions of random matrices generate discrete surfaces with boundaries, 
and thus are in relationship with boundary conformal theory.
A formula for correlation functions representing surfaces with mono-colored boundaries 
has been known since.
It is the aim of this paper to give a formula for a mixed correlation function,
i.e. the generating function for discrete surfaces with a bi-colored boundary.

The 2-matrix model has attracted a lot of attention recently,
 and important progress have been made in the study of the associated bi-orthogonal 
 polynomials.
Here, we will express the mixed correlation function in terms of the bi-orthogonal polynomials.







Definition and notation 

We consider two  Hermitian matrices ,
with a probability measure
&& d (M_1,M_2) := Z_N ^-1 d M_1d M_2
[-(V_1(M_1)+V_2(M_2) -M_1M_2)] , 

&& Z_N := d M_1d M_2
[-(V_1(M_1)+V_2(M_2) -M_1M_2)] ,
where  is the product of Lebesgue measures of
all the independent real and imaginary parts of the components of the
two matrices divided by the square of the volume of the unitary group
 (for later convenience). The functions 
 and  are called the potentials and  must be chosen so as to
make  the integral convergent. The normalization factor
 is called  the "partition function", where the name
"function" refers to its dependence on the two potentials. 

One can rewrite the measure in term of eigenvalues and angular integrals 
:
&& d (M_1,M_2) := Z_N ^-1  (X)^2(Y)^2
[-_i=1 ^N(V_1(x_i)+V_2(y_i) )] e ^U^X
  U V^Y V d Ud V_i=1 ^Nd x_i  d y_i , 

&& X:=diag (x_1,,x_N), Y:=diag (y_1,,y_N), U,V
U(N)

&& Z_N := _i=1 ^Nd x_i  d y_i (X)^2(Y)^2d Ud V
[-_i=1 ^N(V_1(x_i)+V_2(y_i) )] e ^U^X
  U V^Y V  .
where  is the product of the normalized   Haar measure over  .
In the original two Hermitian matrix model, the integration path for the 's 
and 's is the real axis (location of the eigenvalues of a Hermitian 
matrix), however, the model can be generalized
to include complex paths or their homology classes in case  the potentials
are holomorphic or meromorphic.

Correlation functions 

In applications of the two-matrix-model to statistical physics on a random 
surface, one is interested in computing correlation functions
involving traces of products of powers of  and .
Each such correlation function can be expanded in Feynman graphs, which 
represent discrete surfaces with boundaries:
the number of boundaries is the number of traces,
the length of each boundary is the total power of  plus the total power of 
 within the trace.

For instance:



is the generating function for discrete surfaces with one boundary (a circle)
 of length  made of  spins only.



is the generating function for discrete surfaces with one boundary of 
length  made of  spins only.



is the generating function for discrete surfaces with one bi-colored 
boundary of length  made of   spins, followed by   spins.

More generally, 




is the generating function for discrete surfaces with one -colored boundary
of length 
 made of   spins, 
followed by   spins, followed by   spins, , 
followed by   spins.

One may also be interested in "multi-loop" correlators (i.e. more than one 
boundary), for instance:



is the generating function for discrete surfaces with two spin  boundaries,
one of length , the other of length .
More generally, one may consider correlation functions involving an arbitrary 
number of traces, each containing arbitrary words of  and .

The correlation functions, with an arbitrary number of traces, with each trace 
containing powers of only one matrix have been known since the work of 
.
They can be expressed in terms of bi-orthogonal polynomials.

The aim of the present article is to express the mixed correlation function
< M_1^r M_2^s >
in terms of bi-orthogonal polynomials too, and confirm that the key property of 
these models is that all relevant spectral
statistics can be reduced to the computation of the corresponding
biorthogonal polynomials.




Bi-orthogonal polynomials 
 Two sequences of monic polynomials
_n(x) = x^n + , _n(y)=y^n + , n=0,1,are called biorthogonal if they are "orthogonal"  with respect to a coupled measure on the product space:
__ d x d y  _n(x)_m(y) e ^- V_1(x)- V_2(y) +xy  = h_n_mn  ,h_n0 nnorms 

where  and  are  the functions (called potentials )
appearing in the two-matrix model measure ().
It is convenient to introduce the associated quasipolynomial
differentials defined by the formulas
&&_n(x):= 1h_n-1   _n-1 (x)e ^-V_1(x) d x

&&_n(y):= 1h_n-1   _n-1 (y)e ^-V_2(y) d y .In terms of these two sequences of differentials the multiplications
by  and  respectively are represented by semiinfinite square
matrices  and  
 according to the formulae
&&x_n(x) = _m Q_n,m _m(x) ;   y_n(y) = _m
P_m,n _m(y) 

&&Q_n,m =0=P_m,n ,  if  n>m+1.The matrices  and  have a rich structure and satisfy the
"string equation" . However we do not need any of their
properties except for eq. () to derive our present results,
and therefore we refer for further details to where
these models are studied especially in the case of polynomial potentials. We 
also point out that the model can easily be generalized to accommodate
contours of integration other than the real axes leaving
intact all the properties which are relevant to the following computations.






The main result 
Our goal is to prove a  formula for the generating function of the
correlators
(M_1 ^rM_2 ^s)_V_1,V_2  :=  1Z_N  
 d  M_1d M_2
 (M_1 ^rM_2 ^s)(-(V_1(M_1)+V_2(M_2)-M_1M_2)) .
By generating function we mean the formal double Laurent series 
(1x-M_1 1y-M_2 )_V_1,V_2 := _r,s  x^-r-1 y^-s-1 
(M_1 ^rM_2 ^s)_V_1,V_2 .
The main obstacle to this sort of computations so far was posed by
the  "angular integration" over the unitary group .


One can trace in the literature various attempts at this computation using the 
loop equations.
A closed formula was found in the large  limit
 in, but an exact formula for finite  was never 
derived.

Our strategy is that of reducing the computation of ()
or even better () to the computation of the corresponding
biorthogonal polynomials associated with the measure ().

We can now write down the  main  result of the paper which is both simple and 
beautiful:


 




   where  and  are the matrices in eq. () and   
denotes the projector   onto the span of
the first  canonical basis vectors, i.e., the 
matrix with nonzero entries .
Formula () should be properly understood in the sense of
an identity of formal Laurent  series in the variables  and ,
although it would be possible to give an analytic meaning to both sides.
For example from ()  one can easily obtain the
following identities
(M_1 ^rM_2 )_V_1,V_2  = (Q^r P) -1 2
_j=0 ^r-1  ((Q^j)(Q^r-1-j ) - 
(Q^jQ^r-1-j ))
(M_1 ^rM_2 ^2)_V_1,V_2  &=& ( Q^rP^2
) - _k_1+k_2=r-1  
(  (Q^k_1 P) (Q^k_2 )
- (Q^k_1 PQ^k_2 ) 
)
 
&&+  _k_1+k_2+k_3=r-2 
 (
1 3(Q^k_1 Q^k_2  Q^k_3 )  
-1 2 (Q^k_1 Q^k_2 ) (Q^k_3 )
+ 1 6(Q^k_1 )(Q^k_2 )( Q^k_3 )  
)




where now  is  the semiinfinite square
matrix with nonzero entries .







In fact in the course of the proof of eq. () we will also
prove the following strong result for the correlations of 
 which naturally
extends to arbitrary (analytic) functions :
&& (M_1 ^rM_2 ^r) _V_1,V_2  = 

&& =_n=0 ^(r,s) 
(-1)^n (n+1)!  e ^_k x_ky_k   

1&&1x_1 & & x_n+1  & &x_1 ^n-1 & & x_n+1  ^n-1 x_1 ^r & & x_n+1 ^r   

1&&1x_1 & & x_n+1  & &x_1 ^n & & x_n+1  ^n    
 

1&&1y_1 & & y_n+1  & &y_1 ^n-1 & & y_n+1 ^n-1 y_1 ^s & & y_n+1 ^s   

1&&1y_1 & & y_n+1 & &y_1 ^n & & y_n+1 ^n    [K_12 (x_k,y_)]_k,n+1 
 .
The formula can be extended to arbitrary analytic functions  and
 to give 
&& (f(M_1)g(M_2) ) _V_1,V_2  = 

&&  =_n=0 ^ 
(-1)^n (n+1)!  e ^_k x_ky_k  
  

1&&1x_1  && x_n+1  &&x_1 ^n-1 & & x_n+1  ^n-1 f(x_1 )  && f(x_n+1 )   

1&&1x_1 & & x_n+1  & &x_1 ^n & & x_n+1  ^n    
 

1&&1y_1 & & y_n+1  & &y_1 ^n-1 & & y_n+1 ^n-1 g(y_1 ) & &g( y_n+1 )   

1&&1y_1 & & y_n+1 & &y_1 ^n & & y_n+1 ^n    [K_12 (x_k,y_)]_k,n+1 
 Here we have used the kernel constructed from the quasipolynomials, 
K_12 (x,y):= _n=1 ^N _n(x)_n(y) = _n=0 ^N-1 
 _n(x)_n(y)e ^-V_1(x)-V_2(y)  h_n  d x
 d y .   













Proofs of formul () and () 










We want to 
compute the expectation values
(M_1 ^rM_2 ^s)
_V_1,V_2 := 1Z _N  d (M_1,M_2)
(M_1 ^rM_2 ^s).
 We denote by
 and  the spectra of the two
matrices  and by  the relative angles.
 Then we can reduce the integral () to an integral over the spectra of  and
 the unitary group of the relative angles. Indeed we have
&& (M_1^rM_2^s)_V_1,V_2  := 1Z _N  d (M_1,M_2)
(M_1^rM_2^s) = 

&& =1Z _N  _i=1 ^N d x_id y_i e ^-V_1(x_i)-V_2(y_i)  ^2(X)^2(Y)_i,j=1 ^N x_i ^ry_j ^s
_U(N) d U  U_ji ^2 e ^(XU^YU)  ,where , 
and  ,  denote the Vandermonde determinants.
The computation requires the knowledge of the
two-points correlators for the unitary integral in
eq. () which we analyze in the next subsection.


Two-points correlator for the unitary integral 

The computation of this quantity has been considered in the finite 
regime in the two
papers. In was described a complete algorithm that allows  the 
construction of a formula for  the
most general correlator 
U_i_1j_1 U^_k_1l_1 U_i_nj_n U^_k_nl_n _U(N)  
 := _U(N)  d U   U_i_1j_1 U^_k_1l_1 U_i_nj_n U^_k_nl_n  e ^Tr  (XU^YU)  .
Such algorithm involves the introduction of  the parametrization of the
unitary group given by the Gel'fand-Tsetlin coordinates associated to one
of the two matrices ; however the
computation is highly involved and in the problem was not carried 
through
to a completely manageable formula.On the other hand in a very simple closed formula was
proposed for the two-point correlator  in
terms of a generating function, that is
&&_i,j 
a_ib_jU_ji ^2_U(N)  = 
_i,j=1 ^N a_i b_j 
_U(N) d U  U_ji ^2 e ^(XU^YU)  = 

&& =1(X)(Y)  
_S_N  () e ^x_y_()  
_n=0 ^N-1  (-1)^n 
_i_1<i_2<<i_n+1  

  

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n-1 & & x_i_n+1  ^n-1 a_i_1  & & a_i_n+1    

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n & & x_i_n+1  ^n    
 

1&&1y_(i_1) & & y_(i_n+1 ) & &y_(i_1) ^n-1 & & y_(i_n+1 ) ^n-1 b_(i_1)  & & b_(i_n+1 )   

1&&1y_(i_1) & & y_(i_n+1 ) & &y_(i_1) ^n & & y_(i_n+1 )  ^n    ,with the understanding  that the Haar measure of the unitary group 
has been normalized to unity.
This formula will be the starting point of our analysis: however the
 author of did not actually prove the formula but just
 made an educated (and -as it turns out- correct) guess. 

Therefore, before proceeding to proving our main result ()
we want to fill in
the gaps between the full but unpractical algorithm given in and
the practical but unproven formula in.
We do not need the full generality of : our
departure  point is  formula (1.4) ibidem, restricted to the particular case of 
the two-point
correlator.
For the ease of the reader we rewrite the aforementioned  formula in the notation of
our present paper
&& U_1j_1 U^_k_11 U_1 j_n U_k_n1 ^_U(N)  =          _j_1k_1 _j_nk_n  (X)(y_2,,y_N) 
(_k=1 ^N-1  _x_k ^x_k+1  d _k)
 _N-1 (_j_1 )
  _N-1  (_j_n )  _    j_1  (x_ -x_j_1 )_    j_n (x_j_n )  

&&  [ _k=1 ^N
  x_ky_1-_k=1 ^N-1  _ky_1] [  e ^_iy_j+1  ]_i,j=1..N-1   .
Here the Haar measure of the unitary group has been normalized to unity, 
 denotes the Vandermonde
determinant of the  numbers , while  is
the short form for the Vandermonde determinant of the whole spectrum
of the matrix .Eq. () was proven  rigorously in 
for ; however it is straightforward to realize that
the unitary integral in eq. () defines an analytic (in fact
entire) function of the variables  and . Therefore the result
extends to 
statistical ensembles of pairs  of 
normal matrices (We recall that a  normal matrix is a matrix that
  commutes with its Hermitian-transposed. Any such matrix can be
  diagonalized using a unitary transformation (and vice-versa).) 
 with their spectrum on arbitrary paths on the
complex plane. Moreover the  restriction on the order of the
spectrum can be lifted because the result is analytic in the variables
 and can be analytically continued to . We now 
set  in eq. () and hence . Then
we have :
&& U_1i ^2 _U(N) = e ^^Nx_y_1   
    (X)(y_2,,y_N)_i  (x_
_      S_N-1   () _k=1 ^N-1  
_x_k ^x_k+1  
      d _k (_k-x_i) e ^_k(y_(k)+1 -y_1)   = 

&& =e ^^Nx_y_1   
    (X)(y_2,,y_N)_i  (x__
      S_N-1   ()

&& [ (
x_k+1 -x_i y_(k)+1  - y_1  -1(y_(k)+1 -y_1)^2 ) 
e ^x_k+1 (y_(k)+1 -y_1) 
-  (
x_k -x_i y_(k)+1  - y_1  -1(y_(k)+1 -y_1)^2 ) e ^x_k (y_(k)+1 -y_1) 
] = 

&& =e ^^Nx_y_1   
    (X)(Y)_i  (x_1  
(y_
_      S_N-1   ()

&& [ ((x_k+1 -x_i)(y_(k)+1  - y_1) -1) 
e ^x_k+1 (y_(k)+1 -y_1) 
-  (
(x_k -x_i)(y_(k)+1  - y_1) -1) 
e ^x_k (y_(k)+1 -y_1) 
] =
We observe that the  following identity holds
&&e ^^Nx_y_1  _      S_N-1   ()
[ ((x_k+1  -x_i)(y_(k)+1  - y_1)
  -1) e ^x_k+1  (y_(k)+1 -y_1) 
-  (
(x_k -x_i)(y_(k)+1  - y_1) -1) 
e ^x_k (y_(k)+1 -y_1) 
] =

&& =-[( (x_-x_i)(y_m-y_1)-1)e ^x_
y_m ]_,m=1N 
which is realized by performing elementary row operations on the
matrix inside the determinant in () so that the  determinant 
reduces to a
 determinant by use of Laplace's formula. The more general case of the expectation value of the  element 
 is obtained by permutation of the spectrum of the matrix 
      so as to give the formula
U_ji ^2 _U(N) =-1 
    (X)(Y) 

[(
      (x_e ^x_        y_m ]_,m=1N  _i  
(x_        j  (y_This form of Shatashvili's formula () for the case  is
      remarkably simple but not suitable for our later
      purposes. Moreover it is not yet clearly equivalent to
      Morozov's formula   (), which is what we need
      for our computation.
It will be proved in appendix  that the two
formul 
are indeed equivalent.

The correlators 
 and their generating function 




Starting from eq. () and using   formula ()
with  and  
we obtain
&&  _U(N)  d U (X^rU^Y^s U)
 e ^(XU^YU) =
_i,j=1 ^N x_i ^ry_j ^s
_U(N) d U  U_ji ^2 e ^(XU^YU)  = 

&& =1(X)(Y)  
_S_N  () e ^x_y_()  
_n=0 ^N-1  (-1)^n 
_i_1<i_2<<i_n+1  

  

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n-1 & & x_i_n+1  ^n-1 x_i_1 ^r & & x_i_n+1  ^r   

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n & & x_i_n+1  ^n    
 

1&&1y_(i_1) & & y_(i_n+1 ) & &y_(i_1) ^n-1 & & y_(i_n+1 ) ^n-1 y_(i_1) ^s & & y_(i_n+1 ) ^s   

1&&1y_(i_1) & & y_(i_n+1 ) & &y_(i_1) ^n & & y_(i_n+1 )  ^n    ,with the understandings  that we use the normalized  Haar measure over
the unitary group 
 and that for  the ratio of
 determinants should be .
The first observation is that the sum over  does not actually need
to be extended up to the size  of the random matrices because the
determinants will vanish for . The next remark is that
the ratios of determinants actually define certain totally symmetric
polynomials of their arguments of degree  and  respectively:
 in fact they are 
Schur polynomials corresponding to hook Young diagrams 
S_r(x_i_1 ,,x_i_n+1  ) :=
 

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n-1 & & x_i_n+1  ^n-1 x_i_1 ^r & & x_i_n+1  ^r   

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n & & x_i_n+1  ^n      
=  _a_1a_2a_r-n   _k=1 ^r-n  x_i_a_k   
=
 _j_1++j_n+1 =r-n  x_i_1 ^j_1  x_i_n+1  ^j_n+1   ,
and a similar expression for the  part. 
It is interesting to notice that in eq. () the
 characters of the representations of the group  appear; the
 same equation could possibly be derived from the character expansion
 of the integrand. 

The formal generating function of these Schur polynomials is:
Schurgenerating 
_r=0 ^1x^r+1  S_r(x_i_1 ,,x_i_n+1  ) = _k=1 ^n+1  1x-x_i_k  
Eq. () now becomes 


&&d (M_1,M_2)
(M_1^rM_2^s) = _i=1 ^N d (x_i)d (y_i)(X)(Y) 
 
_S_N  () 
e ^x_y_()   && _n=0 ^(r,s)  (-1)^n 
_i_1<i_2<<i_n+1   

S_r(x_i_1 ,,x_i_n+1  )
S_s(y_(i_1) ,,y_(i_n+1 ) )
,
where  and 
.

Using eq. () we have:
&&d (M_1,M_2)
(1x-M_1 1y-M_2 ) = &&=_i=1 ^N d (x_i)d (y_i)(X)(Y) 
 
_S_N  () 
e ^x_y_()  
_n=0 ^N-1  (-1)^n 
_i_1<i_2<<i_n+1   
_k=1 ^n+1  1(x-x_i_k )(y-y_(i_k) )  .
By a relabelling of the 's the sum over  becomes an
overcounting factor :
&&d (M_1,M_2)
(1x-M_1 1y-M_2 ) = &&N!_i=1 ^N d (x_i)d (y_i)(X)(Y)  
e ^x_y_  
_n=0 ^N-1  (-1)^n 
_i_1<i_2<<i_n+1   
_k=1 ^n+1  1(x-x_i_k )(y-y_i_k )  .
This formula allows us to obtain the following expression for the
expectations
&&(1x-M_1 1y-M_2 )_V_1,V_2  = && =N!  Z _N  _i=1 ^N d (x_i)d (y_i)(X)(Y)   
 e ^x_y_  
 _n=0 ^N-1   (-1)^n
_i_1<<i_n+1   
_k=1 ^n+1  1(x-x_i_k )(y-y_i_k ) 
 && =1N! 
_n=0 ^N-1 (-1)^n _,S_N  ()  
_i_1<i_2<<i_n+1   
_j=1 ^N _(j) (x_j)
_(j) (y_j ) e ^x_jy_j  
_k=1 ^n+1  1(x-x_i_k )(y-y_i_k ) 
 .In eq. () we have used the normalized quasi-polynomial
differentials defined in 
(), the fact that, with our normalizations for
the Haar measure of , the partition function is 

(see),
and the identities
&&(X) _k=1 ^N d (x_k)
=(_j=0 ^N-1 h_j ) _S_N  
()_k=1 ^N _(k) (x_k)

&&(Y) _k=1 ^N d (y_k)  = (_j=0 ^N-1 h_j )_S_N 
()_k=1 ^N  _(k) (y_k) ,
which are obtained by replacing the monomials in the Vandermonde
determinants by the biorthogonal polynomials of the same degree.

Proof of formula () 

We are now in the position of proving formula () in a few
strokes. Taking the coefficient of  from the formal generating
function in eq. () we obtain the expression 

&&(M_1 ^rM_2 ^s)_V_1,V_2  = && =1N! 
_n=0 ^(r,s) (-1)^n
_i_1<i_2<<i_n+1    _,S_N  () 
_j=1 ^N _(j) (x_j)
_(j) (y_j ) e ^x_jy_j  S_r(x_[i]_n+1  ) S_s(y_[i]_n+1  )

&& =1N! _n=0 ^(r,s) (-1)^n
_i_1<i_2<<i_n+1    _,S_N  () 
_ji_1,,i_n+1  ^N _(j) (x_j)
_(j) (y_j ) e ^x_jy_j   line 

&&_k=1 ^n+1 _(i_k) (x_i_k )
_(i_k) (y_i_k ) e ^x_i_k y_i_k   S_r(x_[i]_n+1  ) S_s(y_[i]_n+1  ) .
In this formula the notation  means the sequence of
variables  (similarly for the 's) and we
have used the fact that the Schur polynomials  as defined in
()  vanish if the
number of variables is greater than .
Next, the orthogonality relations between the 's and the
's in line ()
 imply that the sum over the permutations  is restricted
to those permutations such that 
 ,  Si_1,i_n+1 
where 
 denotes the group of permutation of the indices .
The restriction on the indices  can be lifted
because the following expression is permutation invariant in the
label of those indices and when two such indices coincide the
corresponding term vanishes due to the alternating form of the
sum. This will produce an overcounting of a factor  which must
be corrected: moreover 
 we can relabel the variables of integration of the integral in line
 ()
from  to 
&&(M_1 ^rM_2 ^s)_V_1,V_2  = && =1N!   _S_N  
_n=0 ^(r,s) (-1)^n (n+1)! 
_i_1,i_2,,i_n+1   _S_n+1   () 
e ^_k^n+1 x_k  y_k    S_r(x_[1,] ) S_s(y_[1,] )_k=1 ^n+1  _i_k (x_k ) 
_i_(k)  (y_k )=

&&  =
_n=0 ^(r,s) (-1)^n (n+1)! 
_i_1,i_2,,i_n+1    _S_n+1   ()  e ^_k^n+1  x_k  y_k   S_r(x_[1,, n+1] )
 S_s(y_[1,, n+1] ) _k=1 ^n+1  _i_k (x_k )
_i_k  (y_^-1 (k) ) = 

&& =
_n=0 ^(r,s) (-1)^n (n+1)! 
_i_1,i_2,,i_n+1    _S_n+1   () 
e ^_k^n+1 x_k  y_k    S_r(x_[1,, n+1] ) S_s(y_[1,,
    n+1] )_k=1 ^n+1  _i_k (x_k ) 
_i_(k)  (y_k )=

&&  =
_n=0 ^(r,s) (-1)^n (n+1)! 
_i_1,i_2,,i_n+1    _S_n+1   ()  e ^_k^n+1  x_k  y_k   S_r(x_[1,, n+1] )
 S_s(y_[1,, n+1] ) _k=1 ^n+1  _i_k (x_k )
_i_k  (y_^-1 (k) ) = 

&& = _n=0 ^(r,s) (-1)^n (n+1)! 
 e ^_k^n+1  x_k  y_k   S_r(x_[1,, n+1] )
 S_s(y_[1,, n+1] )
 [K_12 (x_j,y_)]_j,n+1 
where we have used the
definition of the kernel  given in
eq. ().
This concludes the proof of eq. () from which formula
() follows immediately.






Proof of formula () 
Resuming from eq. () and performing 
a relabelling of the 's and the 's allows to choose , and the
sum over  becomes a combinatorial factor:
&&(1x-M_1 1y-M_2 )_V_1,V_2  =
&& =1N! 
_n=0 ^ (-1)^n Nn+1   _,S_N  () 
_j=1 ^N _(j) (x_j)
_(j) (y_j ) e ^x_jy_j  
_k=1 ^n+1  1(x-x_k )(y-y_k ) 
.
Now, the equations () and () imply that
_(j) (x')
_(j) (y') e ^x'y' 
= _(j),(j)   ,

and
_(j) (x')
_(j) (y') e ^x'y' 
1(x-x')(y-y') 
= W_(j),(j) 
where  is the  square matrix(We remind the
  reader that this matrix should be properly understood as a formal
  power series in inverse powers of  and , although an analytic
  definition could be given in terms of the biorthogonal
  polynomials. However this is unnecessary for the scope of the
  present paper.) :
W:= _N 1x-Q 1y-P  _N ^t .
Therefore  where  is a permutation of the  first indices
only, and we can write:
(1x-M_1 1y-M_2 )_V_1,V_2  
 & = &1N! 
_n=0 ^ (-1)^n Nn+1   _S_N 
_S_n+1  
 () 
_j=1 ^n+1  W_(j),(j) 
& = &
_n=0 ^ (-1)^n ( n+1)! (N-n-1)!   _S_N 
(W_(i),(j) )_i,j=1,,n+1 
.
We note 
and we write:
(1x-M_1 1y-M_2 )_V_1,V_2  
= 
_n=0 ^ (-1)^n (n+1)! (N-n-1)!   
__1_N 
(W__i,_j )_i,j=1,,n+1 
,
where the sum over  disappears and brings a factor :
(1x-M_1 1y-M_2 )_V_1,V_2  
& = & 
_n=0 ^ (-1)^n (n+1)!    
__1_n+1  
(W__i,_j )_i,j=1,,n+1  & = & 
_n=0 ^ (-1)^n ( n+1)!    
__1_n+1  
_S_n+1   ()
_j=1 ^n+1 
W__i,_(j)  
,
and we can replace the sum over distinct 's by a sum over all 's:
(1x-M_1 1y-M_2 )_V_1,V_2  
= 
_n=0 ^ (-1)^n (n+1)!    
_S_n+1   ()
__1,,_n+1  
_j=1 ^n+1 
W__i,_(j)  
.
If  is decomposed into a product of  cyclic permutations
of lengths
, we have:
(1x-M_1 1y-M_2 )_V_1,V_2  
& = &
_n=0 ^ (-1)^n (n+1)!    
_S_n+1   
_j=1 ^N ()  (-1)^l_j()+1 
W^l_j() & = &
-_n=0 ^  1(n+1)!    
_S_n+1   _j=1 ^N ()  (-W^l_j() )
,
Now we use the following Lemma, which is a classical result in combinatorics:

Let  be a function defined on the permutation group of
 elements  with the cluster property , i.e., such that if 

is a decomposition into disjoint permutations of  and 
elements (and hence ) then
G_m() = G_m' (_1) G_m" (_2) .

Under these circumstances  we have the identity
(_m=1 ^  _C_m  x^m m!  G_m()) = 1+ _m=1 ^ 
x^m  m!  _S_m  G_m() ,where  denotes the set of all permutations of maximal
length and has cardinality .
In other words this lemma says that if  has 
the cluster property, then taking the logarithm of the RHS of eq. 
() removes 
all "nonconnected" contributions and returns the "connected
components" only. 
In view of Lemma   let us define
G_m() := _j=1 ^N ()  (-W^l_j() )
which has clearly the cluster property, and we have:
&& 1-(1x-M_1 1y-M_2 )_V_1,V_2 
 =   1+ _m=1 ^ 
1 m!  _S_m  G_m() 
 =  [ _m=1 ^  _C_m  1 m!  G_m() ]  && =  [ -_m=1 ^   W^m m   ]  
 =  [ (_N -W)   ]  
 =  (_N -W) 
This concludes our proof of formula ().



Conclusions 
Formula () is quite simple in spite of the long
computations involved in its proof. It is tempting to imagine that
also more complicated multi-correlators could be reduced to a
computation involving the matrices  and , i.e., to biorthogonal
polynomials. Quite clearly the possibility rests on having a
manageable formula for the generic multi-correlators of the
Itzykson-Zuber-Harish-Chandra integral. There are indications that such
a formula should be derivable: for example it is quite
simple to obtain a  formula for a correlator of entries with the same
first index. Indeed starting from eq. () and proceeding in
the same way we did in order to obtain eq. () one can
easily prove the following formula
_a=1 ^n U_ji_a ^2 _U(N)  = 
(-1)^n n!  [F_m(x_)e ^x_    y_m ]_,m=1N 
 
    (X)(Y)_a=1 ^n _i_a 
      (x_i_a )_j (y_where 
F_m ():=[ (y_m -y_j)^n _a=1 ^n(-x_i_a )  -
  (y_m -y_j)^n-1 _a ^n(-x_i_a ) ++(-1)^n n!
]  =

=_s=0 ^n (-1)^s (y_m -y_j)^n-s d ^s      d ^s  _a=1 ^n(-x_i_a ) .
However the computation for non-equal first indices becomes quickly
extremely complicated at least using the technique in.
Nonetheless we hope that this first computation can break through the
general belief that computations of correlators in multi-matrix models
are not feasible in the finite-N regime due to the angular
integrations.It should also be remarked that for polynomial potentials we could use
the so-called "loop" equations to obtain information on other
correlators. The result, however would be dependent on the specific
form of the potentials and would not provide information on the HCIZ
integral itself.



Let us also mention that this calculation could be generalized to other random
 matrix models, in particular the complex matrix model, which presents many
 similarities with the 2-matrix model.
 The gaussian complex matrix model has attracted lot of attention in string
  theory.
A particular case of the ADS/CFT, is the conjectured duality between 
string-theory in a pp-wave background, and BMN gauge theory.
The gaussian complex-matrix model appears as an effective BMN theory 
in a particular limit, and the computation of mixed correlation functions is very important
 in that model. 
In the gaussian complex matrix model, a formula is known for the 2-point mixed correlator
, but little is known
for other mixed correlation functions.



Equivalence of eq. () and () 








 In this appendix we prove that the two formul ()
      and () are equivalent.
To this end we start from () and  compute
U_ji ^2_U(N)   = -1 
    (X)(Y) 

[(
      (x_e ^x_        y_m ]_,m=1N  _i  
(x_        j  (y_=-1 
    (X)(Y) 
 _S_N   ()
   e ^x_y_()    _        i  (x_        j  (y__N  (
      (x_() -y_j)-1)=

=-1 
    (X)(Y) 
 _S_N   ()
 (-1)^N e ^x_y_()    _        i  (x_        j  (y__N  (1-
      (x_() -y_j))=

=1 
    (X)(Y) 
 _S_N   ()
 (-1)^N+1  e ^x_y_()    _i  
(x_j  (y_

[1 - _(x_() -y_j) +
  __1 <_2   (x__1 -x_i)(y_(_1) -y_j)
 (x__2 -x_i)(y_(_2) -y_j) + ]=

1 
    (X)(Y) 
 _S_N   ()
 (-1)^N+1  e ^x_y_()    _i  
(x_j  (y_
[1 + _n=1 ^N (-1)^n  
__1<_2<<_n 
  _k=1 ^n  (x__k -x_i)(y_(_k) -y_j)
  ]= 

1 
    (X)(Y) 
 _S_N   ()
 (-1)^N+1  e ^x_y_()    _i  
(x_j  (y_
[1 + _n=1 ^N (-1)^n  
__1<_2<<_n     _ki, (_k)j,k 
  _k=1 ^n  (x__k -x_i)(y_(_k) -y_j)
  ]
Let us consider the following subexpression from the above formula
 -1truecm  (-1)^N+1   _i  
(x_j  (y_
[1 + _n=1 ^N (-1)^n  __1<_2<<_n     _ki, (_k)j,k 
  _k=1 ^n  (x__k -x_i)(y_(_k) -y_j)] 
() =  

 -1truecm =(-1)^N+1 
[ 1 _i  
(x_j  (y_+ _n=1 ^N-1 
  (-1)^n __1<_2<<_n 
    _ki, (_k)j,k   _k=1 ^n  (x__k -x_i)(y_(_k) -y_j)  _i  
(x_j  (y_() -y_j)    ]  = 

=(-1)^N+1 
[  1 _i  
(x_j  (y_+ _n=1 ^N-1 
(-1)^n
 __1<_2<<_n     _ki, (_k)j,k 1     _i,_k,k  
(x_() j,(_k),  k  (y_() -y_j)    ]  = 
=[  (-1)^N+1   _i  
(x_j  (y_+ _n=1 ^N-1  
(-1)^N-n+1 
_i_1<<i_N-n : ii_k,
  j(i_k)  1     _k: i_ki  
(x_i_k -x_i)_k:(i_k)j   (y_(i_k) -y_j)    ]
= 

=
[  (-1)^N+1   _i  
(x_j  (y_+ _n=1 ^N-1  
(-1)^n+1 
_i_1<<i_n : ii_k,
  j(i_k)  1     _k: i_ki  
(x_i_k -x_i)_k:(i_k)j   (y_(i_k) -y_j) 
]=

=
[  _n=1 ^N  (-1)^n+1 
_i_1<<i_n : ii_k,
  j(i_k)  1     _k: i_ki  
(x_i_k -x_i)_k:(i_k)j   (y_(i_k) -y_j) 
]=

() = 
[  _n=1 ^N  (-1)^n+1 
_i_1<<i_n   _s=1 ^n (-1)^s _i,i_s 
  (x_i_1 ,,x_i_s  ,x_i_n )_s=1 ^n (-1)^s 
_j,(i_s) 
  (y_(i_1) ,,y_(i_s)  ,y_(i_n) )   
   (x_i_1 ,,x_i_n ) (y_(i_1) ,,y_(i_n) ) 
]=

=  _n=1 ^N  (-1)^n+1 
_i_1<<i_n   
  

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n-1 & & x_i_n+1  ^n-1 _ii_1  & & _ii_n+1    

1&&1x_i_1 & & x_i_n+1  & &x_i_1 ^n & & x_i_n+1  ^n    
 

1&&1y_(i_1) & & y_(i_n+1 ) & &y_(i_1) ^n-1 & & y_(i_n+1 ) ^n-1 _j(i_1)  & & _j(i_n+1 )   

1&&1y_(i_1) & & y_(i_n+1 ) & &y_(i_1) ^n & & y_(i_n+1 )  ^n   In the above chain of equality we have replaced (after the )
the upper limit of summation by  because in the case  there
is certainly one  equal to  (and one  equal
to ) so that that term does not contribute. After  we
have removed the condition on the multi-index because it is implicit
in the sum of deltas that follows.
Putting together eq. () with eq. () or
()  we obtain
the desired proof of the equivalence of formula ()
with eq. (), thus also proving the former rigorously, which
was not done in.



 00 

 D. Berenstein, J. Maldacena, H. Nastase
"Strings in flat space and pp waves from  Super Yang Mills",
JHEP 0204 (2002) 013.

 M. Bertola, "Bilinear semi-classical moment functionals and 
their
  integral representation", J. App. Theory (at press), math.CA/0205160

 M. Bertola, B. Eynard, J. Harnad, "Differential
  systems for biorthogonal polynomials appearing in 2-matrix models
  and the associated Riemann-Hilbert problem", nlin.SI/0208002.

  M. Bertola, B. Eynard, J. Harnad, "Duality of spectral curves 
arising in two-matrix
  models", Theor. Math. Phys. 134  (1), 25-36 (2003).

  M. Bertola, B. Eynard, J. Harnad, "Duality, Biorthogonal 
Polynomials and Multi-Matrix
  Models", Commun. Math. Phys. 229  (2002), 73-120.


 P. Di Francesco, P. Ginsparg, J. Zinn-Justin, "2D Gravity and 
Random Matrices", Phys. Rep.  254 , 1 (1995).

 B. Eynard, "Eigenvalue distribution of large random 
matrices, from one matrix to several coupled matrices", Nuc. Phys. B
506 ,3 
633-664 (1997).  

 B. Eynard, "Large N expansion of the 2-matrix model", JHEP 01 
(2003) 051.

 B. Eynard, C. Kristjansen, 
"BMN Correlators by Loop Equations", JHEP 0210 (2002) 027. 

 B. Eynard, M.L. Mehta, "Matrices coupled in a chain: 
eigenvalue correlations", J. Phys. A: Math. Gen.  31 , 4449 (1998),
cond-mat/9710230. 

 T. Guhr, A. Mueller-Groeling, H.A. Weidenmuller, "Random 
matrix theories in quantum physics: Common concepts", Phys. Rep. 
299 , 189 (1998).

 C. Itzykson and J.B. Zuber, "The planar approximation 
(II)", J. Math. Phys.  21 , 411 (1980).

 A. A. Kapaev, '
'The Riemann-Hilbert Problem for the Bi-Orthogonal Polynomials",
nlin.SI/0207036.

 M.L. Mehta, "A method of integration over matrix 
variables", Commun. Math. Phys.  79 , 327 (1981).

 M.L. Mehta, Random Matrices , 2nd edition, (Academic
Press, New York, 1991).

 A. Morozov, "Pair correlator in the Itzykson-Zuber
Integral", Modern Phys. Lett. A 7 , no. 37 3503-3507 (1992).


 S. L. Shatashvili, "Correlation Functions in the
  Itzykson-Zuber Model", Comm. Math. Phys. 154  421-432
  (1993).

 M. Staudacher, "Combinatorial Solution of the
  Two-Matrix Model", Phys. Lett. B 305  332-338 (1993).












